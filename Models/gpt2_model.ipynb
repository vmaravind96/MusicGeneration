{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3591,"status":"ok","timestamp":1651359023214,"user":{"displayName":"Aravindakumar V M","userId":"01824702113046396419"},"user_tz":360},"id":"n6nkE_hFBFqr","outputId":"13dfb3dd-e301-4b4a-dfff-a80c981214f8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":153,"status":"ok","timestamp":1651359023361,"user":{"displayName":"Aravindakumar V M","userId":"01824702113046396419"},"user_tz":360},"id":"hoFxN_wrWxc_","outputId":"e2dfcba7-36ec-42f6-9cdb-f6bd6c0fbb9a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sat Apr 30 22:50:23 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   45C    P0    32W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wtNsViRYJ2Py"},"outputs":[],"source":["import os\n","import json\n","import numpy as np\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel, TrainingArguments, Trainer, AutoTokenizer, AutoModelForCausalLM\n","from torch.utils.data import Dataset, random_split\n","import torch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1651359028234,"user":{"displayName":"Aravindakumar V M","userId":"01824702113046396419"},"user_tz":360},"id":"2TABEv4YW5TG","outputId":"03d77da9-8e25-4c68-a024-871c368f97db"},"outputs":[{"data":{"text/plain":["1"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.device_count()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5OmvXSKqXrS0"},"outputs":[],"source":["device = \"cuda:0\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H-NUSkg7NFwS"},"outputs":[],"source":["# Path to the input data directory\n","input_data_dir = \"/content/drive/MyDrive/NeuralNets/Project/data/\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":159,"status":"ok","timestamp":1651359028387,"user":{"displayName":"Aravindakumar V M","userId":"01824702113046396419"},"user_tz":360},"id":"89ShWBrN99Zl","outputId":"d0e7b088-7509-49f5-91a1-fb65b0b23ac0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing file:  ash.txt\n","File name: ash.txt, # Samples: 46\n","Processing file:  christ.txt\n","File name: christ.txt, # Samples: 13\n","Processing file:  hornpipes.txt\n","File name: hornpipes.txt, # Samples: 65\n","Processing file:  jigs.txt\n","File name: jigs.txt, # Samples: 340\n","Processing file:  morris.txt\n","File name: morris.txt, # Samples: 31\n","Processing file:  mq.txt\n","File name: mq.txt, # Samples: 80\n","Processing file:  playford.txt\n","File name: playford.txt, # Samples: 15\n","Processing file:  reelsac.txt\n","File name: reelsac.txt, # Samples: 81\n","Processing file:  reelsdg.txt\n","File name: reelsdg.txt, # Samples: 84\n","Processing file:  reelshl.txt\n","File name: reelshl.txt, # Samples: 93\n","Processing file:  rt.txt\n","File name: rt.txt, # Samples: 92\n","Processing file:  slipjigs.txt\n","File name: slipjigs.txt, # Samples: 11\n","Processing file:  uz.txt\n","File name: uz.txt, # Samples: 34\n","Processing file:  waltzes.txt\n","File name: waltzes.txt, # Samples: 52\n","Total samples obtained: 1037\n"]}],"source":["total_samples = 0\n","data = []\n","text_to_ignore = [\"% continue here %\"]\n","for fname in os.listdir(input_data_dir):\n","    if fname.endswith(\".txt\") and fname not in [\"combined.txt\"]:\n","      print(\"Processing file: \", fname)\n","      f_path = os.path.join(input_data_dir, fname)\n","      with open(f_path, \"r\") as fp:\n","        content = [sample for sample in fp.read().split('\\n\\n') if len(sample)>0 and sample not in text_to_ignore]\n","        print(f\"File name: {fname}, # Samples: {len(content)}\")\n","        total_samples += len(content)\n","        data.extend(content)\n","\n","print(f\"Total samples obtained: {total_samples}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1127,"status":"ok","timestamp":1651359029512,"user":{"displayName":"Aravindakumar V M","userId":"01824702113046396419"},"user_tz":360},"id":"u1gR_Mq_Dt4i","outputId":"0014cbc9-1be5-4b85-af92-706ff01b0d3c"},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["# Initialize the tokenizer\n","tokenizer = AutoTokenizer.from_pretrained('distilgpt2', \n","                                          bos_token='<|startoftext|>',\n","                                          eos_token='<|endoftext|>', \n","                                          pad_token='<|pad|>')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":302},"executionInfo":{"elapsed":862,"status":"ok","timestamp":1651359030372,"user":{"displayName":"Aravindakumar V M","userId":"01824702113046396419"},"user_tz":360},"id":"8wWdzYeEehh8","outputId":"c2cd3f55-070c-4d55-853b-8276ad36ed40"},"outputs":[{"name":"stderr","output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 1024). Running this sequence through the model will result in indexing errors\n"]},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPMElEQVR4nO3da6ylV13H8e/PDi2G2/Ry0jQzo6dI1fSNtE5wDJcYKtALMlWBlBA74iQTk5JA0OAgiWLii1YjVaKBjLZhahCKXNIJYKCWIvFFC9MylF4oPa1tOpNpZ2hLC0HQwt8Xew3uGc91Zt9m+f0kO3s961n7PP+z9j6/85y1LydVhSSpLz817QIkSaNnuEtShwx3SeqQ4S5JHTLcJalD66ZdAMBZZ51V8/Pz0y5Dkk4qd9xxx7eram6xfTMR7vPz8+zdu3faZUjSSSXJI0vtc1lGkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6NBPvUD1Zze/87FSO+/DVl03luJJOHp65S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQyf9P8ie1j+plqRZ5pm7JHXIcJekDhnuktQhw12SOrTqcE9ySpKvJflM2z43ye1JFpLcmOTU1n9a215o++fHU7okaSlrOXN/B3Df0PY1wLVV9RLgKWB7698OPNX6r23jJEkTtKpwT7IRuAz4h7Yd4NXAJ9qQ3cDlrb21bdP2X9TGS5ImZLVn7n8NvBv4cds+E/hOVT3btvcDG1p7A/AoQNv/dBt/lCQ7kuxNsvfw4cPHWb4kaTErhnuS1wOHquqOUR64qnZV1eaq2jw3NzfKLy1J/++t5h2qLwfekORS4LnAC4G/AdYnWdfOzjcCB9r4A8AmYH+SdcCLgCdGXrkkaUkrnrlX1XuqamNVzQNXAF+sqrcCtwJvbMO2ATe19p62Tdv/xaqqkVYtSVrWibzO/Y+AdyVZYLCmfl3rvw44s/W/C9h5YiVKktZqTR8cVlVfAr7U2g8BL1tkzA+AN42gNknScfIdqpLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nq0IrhnuS5Sb6S5OtJ7knyZ63/3CS3J1lIcmOSU1v/aW17oe2fH++3IEk61mrO3H8IvLqqfgl4KXBxki3ANcC1VfUS4Clgexu/HXiq9V/bxkmSJmjFcK+B77XN57RLAa8GPtH6dwOXt/bWtk3bf1GSjKxiSdKKVrXmnuSUJPuAQ8DNwIPAd6rq2TZkP7ChtTcAjwK0/U8DZy7yNXck2Ztk7+HDh0/su5AkHWVV4V5VP6qqlwIbgZcBv3iiB66qXVW1uao2z83NneiXkyQNWdOrZarqO8CtwK8C65Osa7s2Agda+wCwCaDtfxHwxEiqlSStympeLTOXZH1r/zTwGuA+BiH/xjZsG3BTa+9p27T9X6yqGmXRkqTlrVt5COcAu5OcwuCXwcer6jNJ7gU+luTPga8B17Xx1wH/mGQBeBK4Ygx1S5KWsWK4V9VdwAWL9D/EYP392P4fAG8aSXWSpOPiO1QlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOrRjuSTYluTXJvUnuSfKO1n9GkpuTPNCuT2/9SfKBJAtJ7kpy4bi/CUnS0VZz5v4s8AdVdT6wBbgqyfnATuCWqjoPuKVtA1wCnNcuO4APjrxqSdKyVgz3qjpYVXe29neB+4ANwFZgdxu2G7i8tbcCN9TAbcD6JOeMvHJJ0pLWtOaeZB64ALgdOLuqDrZdjwFnt/YG4NGhm+1vfcd+rR1J9ibZe/jw4TWWLUlazqrDPcnzgU8C76yqZ4b3VVUBtZYDV9WuqtpcVZvn5ubWclNJ0gpWFe5JnsMg2D9SVZ9q3Y8fWW5p14da/wFg09DNN7Y+SdKErObVMgGuA+6rqvcP7doDbGvtbcBNQ/1XtlfNbAGeHlq+kSRNwLpVjHk58DvAN5Lsa31/DFwNfDzJduAR4M1t3+eAS4EF4PvA20ZasSRpRSuGe1X9O5Aldl+0yPgCrjrBuiRJJ8B3qEpShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOrZt2AVq7+Z2fndqxH776sqkdW9LqeeYuSR0y3CWpQ4a7JHXIcJekDq0Y7kmuT3Ioyd1DfWckuTnJA+369NafJB9IspDkriQXjrN4SdLiVnPm/mHg4mP6dgK3VNV5wC1tG+AS4Lx22QF8cDRlSpLWYsVwr6ovA08e070V2N3au4HLh/pvqIHbgPVJzhlVsZKk1TneNfezq+pgaz8GnN3aG4BHh8btb33/R5IdSfYm2Xv48OHjLEOStJgTfkK1qgqo47jdrqraXFWb5+bmTrQMSdKQ4w33x48st7TrQ63/ALBpaNzG1idJmqDjDfc9wLbW3gbcNNR/ZXvVzBbg6aHlG0nShKz42TJJPgr8GnBWkv3AnwJXAx9Psh14BHhzG/454FJgAfg+8LYx1CxJWsGK4V5Vb1li10WLjC3gqhMtSpJ0YnyHqiR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHVo37QJ0cpnf+dmpHPfhqy+bynGlk5Vn7pLUIcNdkjpkuEtSh1xz10nBtX5pbcZy5p7k4iT3J1lIsnMcx5AkLW3kZ+5JTgH+DngNsB/4apI9VXXvqI8ljdu0/mIA/2rQiRnHsszLgIWqegggyceArYDhLmkm9fhLfBzhvgF4dGh7P/Arxw5KsgPY0Ta/l+R+4Czg22OoaRRmtbZZrQtmt7ZZrQuGass1U67kaCfFnM2YVdV1gvfzzy61Y2pPqFbVLmDXcF+SvVW1eUolLWtWa5vVumB2a5vVumB2a5vVumB2a5t2XeN4QvUAsGloe2PrkyRNyDjC/avAeUnOTXIqcAWwZwzHkSQtYeTLMlX1bJK3A58HTgGur6p7VnnzXSsPmZpZrW1W64LZrW1W64LZrW1W64LZrW2qdaWqpnl8SdIY+PEDktQhw12SOjQz4T7NjyxIsinJrUnuTXJPkne0/vclOZBkX7tcOnSb97Ra70/yujHX93CSb7Qa9ra+M5LcnOSBdn1660+SD7Ta7kpy4Zhq+oWhedmX5Jkk75zWnCW5PsmhJHcP9a15jpJsa+MfSLJtTHX9ZZJvtmN/Osn61j+f5D+H5u5DQ7f55fYYWGi1Z0y1rfn+G/XP7hJ13ThU08NJ9rX+ic3ZMjkx9cfZoqpq6hcGT7w+CLwYOBX4OnD+BI9/DnBha78A+BZwPvA+4A8XGX9+q/E04NxW+yljrO9h4Kxj+v4C2NnaO4FrWvtS4F+AAFuA2yd0/z3G4A0VU5kz4FXAhcDdxztHwBnAQ+369NY+fQx1vRZY19rXDNU1PzzumK/zlVZrWu2XjGnO1nT/jeNnd7G6jtn/V8CfTHrOlsmJqT/OFrvMypn7Tz6yoKr+CzjykQUTUVUHq+rO1v4ucB+Dd9ouZSvwsar6YVX9B7DA4HuYpK3A7tbeDVw+1H9DDdwGrE9yzphruQh4sKoeWWbMWOesqr4MPLnIMdcyR68Dbq6qJ6vqKeBm4OJR11VVX6iqZ9vmbQzeC7KkVtsLq+q2GqTDDUPfy0hrW8ZS99/If3aXq6udfb8Z+OhyX2Mcc7ZMTkz9cbaYWQn3xT6yYLlwHZsk88AFwO2t6+3tT6rrj/y5xeTrLeALSe7I4GMbAM6uqoOt/Rhw9pRqg8F7GYZ/2GZhzmDtczSNGn+PwdndEecm+VqSf0vyyta3odUyqbrWcv9Nes5eCTxeVQ8M9U18zo7JiZl8nM1KuM+EJM8HPgm8s6qeAT4I/BzwUuAggz8Hp+EVVXUhcAlwVZJXDe9sZyZTeU1rBm9UewPwz61rVubsKNOco6UkeS/wLPCR1nUQ+JmqugB4F/BPSV444bJm8v4b8haOPpGY+JwtkhM/MUuPs1kJ96l/ZEGS5zC4wz5SVZ8CqKrHq+pHVfVj4O/532WEidZbVQfa9SHg062Ox48st7TrQ9OojcEvnDur6vFW40zMWbPWOZpYjUl+F3g98NYWCLQljyda+w4Ga9k/32oYXroZW13Hcf9Ncs7WAb8F3DhU70TnbLGcYEYfZ7MS7lP9yIK2jncdcF9VvX+of3it+jeBI8/e7wGuSHJaknOB8xg8eTOO2p6X5AVH2gyejLu71XDkWfZtwE1DtV3ZnqnfAjw99CfjOBx1JjULczZkrXP0eeC1SU5vyxGvbX0jleRi4N3AG6rq+0P9cxn8PwSSvJjBHD3UansmyZb2WL1y6HsZdW1rvf8m+bP768A3q+onyy2TnLOlcoIZfZyN9NnZE7kweGb5Wwx+8753wsd+BYM/pe4C9rXLpcA/At9o/XuAc4Zu895W6/2M4JULy9T2YgavQPg6cM+RuQHOBG4BHgD+FTij9YfBP0t5sNW+eYy1PQ94AnjRUN9U5ozBL5iDwH8zWMPcfjxzxGANfKFd3jamuhYYrLkeeax9qI397XYf7wPuBH5j6OtsZhC0DwJ/S3t3+RhqW/P9N+qf3cXqav0fBn7/mLETmzOWzompP84Wu/jxA5LUoVlZlpEkjZDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjr0PxlCqNoxXc4mAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","\n","plt.hist([len(tokenizer.encode(sample)) for sample in data])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uT8dMZuve9sP"},"outputs":[],"source":["max_length = 1024"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uryF4Lo1OaqI"},"outputs":[],"source":["class MusicDataSet(Dataset):\n","    def __init__(self, txt_list, tokenizer, max_length):\n","        self.input_ids = []\n","        self.attn_masks = []\n","        self.labels = []\n","        for txt in txt_list:\n","            encodings_dict = tokenizer('<|startoftext|>' + txt[:1022] + '<|endoftext|>', truncation=True,\n","                                       max_length=max_length, padding=\"max_length\")\n","            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n","            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n","\n","    def __len__(self):\n","        return len(self.input_ids)\n","\n","    def __getitem__(self, idx):\n","        return self.input_ids[idx], self.attn_masks[idx]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Mcx2OIkOjbD"},"outputs":[],"source":["# Initialize torch\n","dataset = MusicDataSet(data, tokenizer, 1024)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kJU2tAgCSseO"},"outputs":[],"source":["# Train and Validation split\n","train_size = int(0.9 * len(dataset))\n","train_dataset, val_dataset = random_split(dataset, [train_size, len(dataset) - train_size])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6779,"status":"ok","timestamp":1651359038259,"user":{"displayName":"Aravindakumar V M","userId":"01824702113046396419"},"user_tz":360},"id":"pPnwgAQ3P3sP","outputId":"0857796a-d5cf-4c4b-e544-28ee044400e1"},"outputs":[{"data":{"text/plain":["Embedding(50259, 768)"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# Initialize Model\n","model = AutoModelForCausalLM.from_pretrained('distilgpt2').cuda()\n","model.resize_token_embeddings(len(tokenizer))\n","# model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1651359038401,"user":{"displayName":"Aravindakumar V M","userId":"01824702113046396419"},"user_tz":360},"id":"RxeT5YsrVbS8","outputId":"2b7598ab-2d03-4352-b21c-51fa25c8aba7"},"outputs":[{"data":{"text/plain":["3287"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["import gc\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nG5X0q6zT0yV"},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lVePyMKZP7tB"},"outputs":[],"source":["# Initialize Training Arguments\n","training_args = TrainingArguments(output_dir=\"./output\", num_train_epochs=20, weight_decay=0.05, per_device_train_batch_size=1, per_device_eval_batch_size=1, warmup_steps=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"id":"oo6Hu56zQ9y9","outputId":"a027db18-29dd-453c-ffae-acc8278eb93e"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 933\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 1\n","  Total train batch size (w. parallel, distributed & accumulation) = 1\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 18660\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='18660' max='18660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [18660/18660 42:54, Epoch 20/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.608100</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.419200</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.368500</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.357000</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.332800</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.319300</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.307300</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.295100</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.290900</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.284300</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.269300</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.274000</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.258400</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.249400</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>0.255300</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.237400</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>0.246900</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>0.239000</td>\n","    </tr>\n","    <tr>\n","      <td>9500</td>\n","      <td>0.237600</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>0.225000</td>\n","    </tr>\n","    <tr>\n","      <td>10500</td>\n","      <td>0.225700</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>0.226800</td>\n","    </tr>\n","    <tr>\n","      <td>11500</td>\n","      <td>0.216500</td>\n","    </tr>\n","    <tr>\n","      <td>12000</td>\n","      <td>0.214200</td>\n","    </tr>\n","    <tr>\n","      <td>12500</td>\n","      <td>0.214800</td>\n","    </tr>\n","    <tr>\n","      <td>13000</td>\n","      <td>0.213900</td>\n","    </tr>\n","    <tr>\n","      <td>13500</td>\n","      <td>0.203200</td>\n","    </tr>\n","    <tr>\n","      <td>14000</td>\n","      <td>0.210500</td>\n","    </tr>\n","    <tr>\n","      <td>14500</td>\n","      <td>0.200700</td>\n","    </tr>\n","    <tr>\n","      <td>15000</td>\n","      <td>0.203900</td>\n","    </tr>\n","    <tr>\n","      <td>15500</td>\n","      <td>0.198400</td>\n","    </tr>\n","    <tr>\n","      <td>16000</td>\n","      <td>0.200800</td>\n","    </tr>\n","    <tr>\n","      <td>16500</td>\n","      <td>0.195000</td>\n","    </tr>\n","    <tr>\n","      <td>17000</td>\n","      <td>0.197200</td>\n","    </tr>\n","    <tr>\n","      <td>17500</td>\n","      <td>0.189900</td>\n","    </tr>\n","    <tr>\n","      <td>18000</td>\n","      <td>0.192100</td>\n","    </tr>\n","    <tr>\n","      <td>18500</td>\n","      <td>0.194800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./output/checkpoint-500\n","Configuration saved in ./output/checkpoint-500/config.json\n","Model weights saved in ./output/checkpoint-500/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-1000\n","Configuration saved in ./output/checkpoint-1000/config.json\n","Model weights saved in ./output/checkpoint-1000/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-1500\n","Configuration saved in ./output/checkpoint-1500/config.json\n","Model weights saved in ./output/checkpoint-1500/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-2000\n","Configuration saved in ./output/checkpoint-2000/config.json\n","Model weights saved in ./output/checkpoint-2000/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-2500\n","Configuration saved in ./output/checkpoint-2500/config.json\n","Model weights saved in ./output/checkpoint-2500/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-3000\n","Configuration saved in ./output/checkpoint-3000/config.json\n","Model weights saved in ./output/checkpoint-3000/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-3500\n","Configuration saved in ./output/checkpoint-3500/config.json\n","Model weights saved in ./output/checkpoint-3500/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-4000\n","Configuration saved in ./output/checkpoint-4000/config.json\n","Model weights saved in ./output/checkpoint-4000/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-4500\n","Configuration saved in ./output/checkpoint-4500/config.json\n","Model weights saved in ./output/checkpoint-4500/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-5000\n","Configuration saved in ./output/checkpoint-5000/config.json\n","Model weights saved in ./output/checkpoint-5000/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-5500\n","Configuration saved in ./output/checkpoint-5500/config.json\n","Model weights saved in ./output/checkpoint-5500/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-6000\n","Configuration saved in ./output/checkpoint-6000/config.json\n","Model weights saved in ./output/checkpoint-6000/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-6500\n","Configuration saved in ./output/checkpoint-6500/config.json\n","Model weights saved in ./output/checkpoint-6500/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-7000\n","Configuration saved in ./output/checkpoint-7000/config.json\n","Model weights saved in ./output/checkpoint-7000/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-7500\n","Configuration saved in ./output/checkpoint-7500/config.json\n","Model weights saved in ./output/checkpoint-7500/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-8000\n","Configuration saved in ./output/checkpoint-8000/config.json\n","Model weights saved in ./output/checkpoint-8000/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-8500\n","Configuration saved in ./output/checkpoint-8500/config.json\n","Model weights saved in ./output/checkpoint-8500/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-9000\n","Configuration saved in ./output/checkpoint-9000/config.json\n","Model weights saved in ./output/checkpoint-9000/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-9500\n","Configuration saved in ./output/checkpoint-9500/config.json\n","Model weights saved in ./output/checkpoint-9500/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-10000\n","Configuration saved in ./output/checkpoint-10000/config.json\n","Model weights saved in ./output/checkpoint-10000/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-10500\n","Configuration saved in ./output/checkpoint-10500/config.json\n","Model weights saved in ./output/checkpoint-10500/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-11000\n","Configuration saved in ./output/checkpoint-11000/config.json\n","Model weights saved in ./output/checkpoint-11000/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-11500\n","Configuration saved in ./output/checkpoint-11500/config.json\n","Model weights saved in ./output/checkpoint-11500/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-12000\n","Configuration saved in ./output/checkpoint-12000/config.json\n","Model weights saved in ./output/checkpoint-12000/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-12500\n","Configuration saved in ./output/checkpoint-12500/config.json\n","Model weights saved in ./output/checkpoint-12500/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-13000\n","Configuration saved in ./output/checkpoint-13000/config.json\n","Model weights saved in ./output/checkpoint-13000/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-13500\n","Configuration saved in ./output/checkpoint-13500/config.json\n","Model weights saved in ./output/checkpoint-13500/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-14000\n","Configuration saved in ./output/checkpoint-14000/config.json\n","Model weights saved in ./output/checkpoint-14000/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-14500\n","Configuration saved in ./output/checkpoint-14500/config.json\n","Model weights saved in ./output/checkpoint-14500/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-15000\n","Configuration saved in ./output/checkpoint-15000/config.json\n","Model weights saved in ./output/checkpoint-15000/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-15500\n","Configuration saved in ./output/checkpoint-15500/config.json\n","Model weights saved in ./output/checkpoint-15500/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-16000\n","Configuration saved in ./output/checkpoint-16000/config.json\n","Model weights saved in ./output/checkpoint-16000/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-16500\n","Configuration saved in ./output/checkpoint-16500/config.json\n","Model weights saved in ./output/checkpoint-16500/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-17000\n","Configuration saved in ./output/checkpoint-17000/config.json\n","Model weights saved in ./output/checkpoint-17000/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-17500\n","Configuration saved in ./output/checkpoint-17500/config.json\n","Model weights saved in ./output/checkpoint-17500/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-18000\n","Configuration saved in ./output/checkpoint-18000/config.json\n","Model weights saved in ./output/checkpoint-18000/pytorch_model.bin\n","Saving model checkpoint to ./output/checkpoint-18500\n","Configuration saved in ./output/checkpoint-18500/config.json\n","Model weights saved in ./output/checkpoint-18500/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"data":{"text/plain":["TrainOutput(global_step=18660, training_loss=0.25812703609977633, metrics={'train_runtime': 2574.9075, 'train_samples_per_second': 7.247, 'train_steps_per_second': 7.247, 'total_flos': 4875797366046720.0, 'train_loss': 0.25812703609977633, 'epoch': 20.0})"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["Trainer(\n","model=model,  \n","args=training_args, \n","train_dataset=train_dataset, \n","eval_dataset=val_dataset,\n","data_collator=lambda data: {\n","    'input_ids': torch.stack([f[0] for f in data]),\n","    'attention_mask': torch.stack([f[1] for f in data]),\n","    'labels': torch.stack([f[0] for f in data])}\n",").train()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"63RDd2GBWrAM"},"outputs":[],"source":["generated = tokenizer(\"<|startoftext|> \", return_tensors=\"pt\").input_ids.cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"1eqEJlq5SlZz","outputId":"77c470f5-5a3d-4c5f-b0f5-d0f99e3d496f"},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]}],"source":["sample_outputs = model.generate(generated, do_sample=True, top_k=50, max_length=1024, top_p=0.95, temperature=1.9, num_return_sequences=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"OXPr-QSOSuuh","outputId":"aea55d9d-8b6e-45b3-cc62-74264f920820"},"outputs":[{"name":"stdout","output_type":"stream","text":["0:   Super Lucky Day here in California\n","Kerrs/2E4\n","Taken by Jacquie\n","M:4/4\n","L:1/4\n","P:ABCB\n","P:A\n","D|B/2c/2\"D7 [FA']|\"G\"G3/2d/2 GB|\"F\"Ac/2d -\"Em\"dd|c3d|\"Ab dAz|\n","2a/2e/2e|e/2F df|AG FA|[ECA7]E2 F\\\n","P:DA[FEFE ][2 A3/2B/2|\n","\"D7\"dz|c/2A/2F A|\"Em\"Ge B3/2F/2G/2|AG F#:3 [M:4/4L]F/4|\\\n","\"Em\"GF E3c/2B,|\"A7\"(3AG/2F/2 EC|\n","\"D7\"GE =DC\\\n","P :D.S.F |\"G\"gg f3/2e/2|\"E7\"(3GHD)DE|GE F^D|\"C\"cA ef|\n","\"GA-\"(c/2e/2d ga|^fac cAc|eB D^D|GA+=d|\n","M:3.48\\\n","!=e|!sevent!P :D.S.D.F.C |\n","***********************************************************************\n","1:    'G'W3 - -U'z\n","P:Idolia Pet\n","T:Viper\n","% ABBA times 31\n","% Nottingham Music Database\n","S:O'Neils 1850 Bc+D|\"O-\"C\"GEF DEF|\"C\"EFG \"Babag\"Bee|\"G\"de-fa b2g \"G7\"agf|\n","B7\"gfg fee g2e|agf bag|efe dcB|ecA FA|fe dcA|\n","FA A,G,2A||B, EFG ||B,EE AGEC|[1 AG^FAE EFG:|2AGE\n","2|!-B^AB ^c^d=c|dBB ABBA (B^AceAc|G^F E=GG|[2 AGAB \\\n","P:3.31\n","CAG |%P:3\n","FA DE|Edd ddd|=GeF de_de|Ac cdB|GA_B =BcAG|\n","^F EE_D|_FF f4-|AfE dcGA|\n","^F E=FF eee||FE4|\\\n","P:Vigab af edc|GA_B2 A^G_G_||\n","***********************************************************************\n","2:   Rose MacKenzie of Liverpool\n","S:Fishers\n","M:4/4\n","L:1/4\n","K:Em\n","D|\n","c|e3/2E/2 AE|\n","F/2G/2 Fc|\"Bm\"d2e fe|fd2B|GB DB|^G2 Fd|\"Gdim\"\"Em\"G3c|\"Bm\"Bd2f f2::\n","e/2d/2|\"C\"efg ac|d=f c^c|\"G\"BGF G=F^G\\\n","|\"Em\"GF G3|\"Bm\"fed fe|\n","f/2Gc BA|\"Em\"GF GBc/2e/2|\"D\"fed ed|a\"f2:|\n","***********************************************************************\n","3:  ia yborim out of my way.\n","M:4/4\n","L:1/4\n","K:G\n","P:C\n","D3/2DE f/2ef ed|\"C\"(7)ce ec3/2A/2|g4\"B|c\"EA a3e/2g/2|^f/2g/2 ce|gg e3\n","ag|\"D\"fd fff|_efe dcB|AB2 fe|a gfe|_Bc d2:|\n","***********************************************************************\n","4:   from BAG?\n","X: 19\n","T:Barry Blarney\n","% Nottingham Music Database\n","S:Mick Peat\n","M:4/4\n","L:1/4\n","K:G\n","P:G\n","B2|:\"G\"GD/2^B/2 dB/2d/2|eg eg \"C\"Ge/2d/2|\"G\"dBG BG/2A/2|\"Am\"Bg e/2(3ecd/2d/2^c/2|\\\n","\"Am\"ed cA:|\n","(3ed/2d/2^c d_e|  def\\\n","g2g|\"G/ef/2e/2 fa| ecd \"G\"d2e|!trill!trill!  \"C\"eg \"G\"BG:|\n","P:G\n","d|:\\\n","***********************************************************************\n"]}],"source":["for i, sample_output in enumerate(sample_outputs):\n","    print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n","    print(\"***********************************************************************\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"fmRAJmLXSzhg"},"outputs":[],"source":["# Save the model\n","trained_model_weight_path = input_data_dir + \"trained_distillgpt2.h5\"\n","torch.save(model, trained_model_weight_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"carZYHQKWBda"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","name":"gpt2_model.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}